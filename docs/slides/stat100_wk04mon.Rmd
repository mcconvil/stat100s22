---
title: Data Collection
output:
  xaringan::moon_reader:
    css: ["more.css", "xaringan-themer.css", "hygge"]
    lib_dir: libsSlides
    self_contained: false
    nature:
      highlightStyle: github
      ratio: '16:9'      
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false
    seal: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = 'center',
                      fig.asp = 0.75, fig.width = 8,
                      cache = TRUE)
library(knitr)
library(tidyverse)
theme_update(text = element_text(size = 20))
```

```{r xaringan-scribble, echo=FALSE}
xaringanExtra::use_scribble()
```


background-image: url("img/DAW.png")
background-position: left
background-size: 50%
class: middle, center, inverse


.pull-right[



## .whitish[Data Collection]

<br>

<br>

### .whitish[Kelly McConville]

#### .yellow[ Stat 100 | Week 4 | Spring 2022] 

]



---

## Announcements


* Make sure to start working on Project Assignment 1 with your group members.
* P-Set 3 due now on Friday at 5pm because of server hiccup.



****************************

--

## Goals for Today

.pull-left[

* Go through data joins.

] 

--

.pull-right[


* Discuss data collection/acquisition.

]


---

## Data Joins

* Often in the data analysis workflow, we have more than one data source, which means more than one dataframe, and we want to combine these dataframes.

--

* Need principled way to combine.
    + Need a **key** that links two dataframes together.

--

* These multiple dataframes are called **relational data**.

<!-- --- -->

<!-- ## Data Joins: Language -->

<!-- Three families of verbs for working with relational data: -->

<!-- -- -->

<!-- * **Mutating joins**: Add variables to one data frame but matching observations in another. -->

<!-- -- -->

<!-- * **Filtering joins**: Filter observations from one data frame based on whether or not they match an observation in the other table. -->

<!-- -- -->

<!-- * **Set operations**: treat observations as if they were set elements. -->

    
---

## Example: BLS Consumer Expenditure Data

* Household survey but data are also collected on individuals
    + fmli: household data
    + memi: household member-level data

```{r}
#Read in data with readr package
library(tidyverse)
fmli <- read_csv("~/shared_data/stat100/data/fmli.csv", 
                 na = c("NA", "."))
memi <- read_csv("~/shared_data/stat100/data/memi.csv", 
                 na = c("NA", "."))

```

* Want variables on principal earner to be added to the household data

---

## CE Data

* Key variable(s)?

```{r}
library(dplyr)
glimpse(fmli)
```

---


## CE Data

* Key variables?

```{r}
glimpse(memi)
```

---

## CE Data

* Key variables?
    + Problem with class?

```{r}
glimpse(select(fmli, 1,2))
glimpse(select(memi, 1:2))
```

---

## CE Data

* Key variables?
    + Problem with class?

```{r}
fmli <- mutate(fmli, PRINEARN = as.integer(PRINEARN))
glimpse(select(fmli, 1, 2))
glimpse(select(memi, 1, 2))
```

---

## CE Data

* Want to add columns of `memi` to `fmli` that correspond to the principal earner's memi data
    + What type of join is that?

---

## The World of Joins

* Mutating joins: Add new variables to one dataset from matching observations in another.
    + `left_join()` (and `right_join()`)
    + `inner_join()`
    + `full_join()`

* There are also *filtering* joins but we won't cover those today.    

---

## Example Dataframes

```{r}
d1 <- tibble(V = 1:5, X = c(1, 2, 2, 3, 1), Y = c(14, 3, 6, 1, 4))
d2 <- tibble(X = c(2, 4, 1), S = c(4, 13, 8))
d1
d2
```

---

## `left_join()`

```{r, message=TRUE, warning=TRUE}
d1_new <- left_join(d1, d2)
d1_new
```

---

## `left_join()`

```{r}
d1_new <- left_join(d1, d2, by = c("X" = "X"))
d1_new
```

---

## `left_join()`

```{r}
d1_new <- left_join(d1, d2, by = c("V" = "X"))
d1_new
```

---

## `inner_join()`

```{r}
d1_d2 <- inner_join(d1, d2, by = c("X" = "X"))
d1_d2
```

---

## `inner_join()`

```{r}
d1_d2 <- inner_join(d1, d2, by = c("V" = "X"))
d1_d2
```

---

## `full_join()`

```{r}
d1_d2 <- full_join(d1, d2, by = c("X" = "X"))
d1_d2
```

---

## `full_join()`

```{r}
d1_d2 <- full_join(d1, d2, by = c("V" = "X"))
d1_d2
```

---

## Back to our Example

* What kind of join do we want for the Consumer Expenditure data?
    + Want to add columns of `memi` to `fmli` that correspond to the principal earner's memi data

---

## Look at the Possible Joins

```{r, message=TRUE, warning=TRUE}
left_join(fmli, memi) %>% 
  arrange(NEWID)
```

---

## Look at the Possible Joins

* Be careful.  This erroneous example made my R crash!

```{r, eval = FALSE}
left_join(fmli, memi, by = c("PRINEARN" = "MEMBNO")) %>% 
  arrange(MEMBNO)
```

---

## Look at the Possible Joins

```{r}
left_join(fmli, memi, by = c("NEWID" = "NEWID",
                             "PRINEARN" = "MEMBNO")) %>% 
  arrange(NEWID)
```

---

## Look at the Possible Joins

```{r}
inner_join(fmli, memi, by = c("NEWID" = "NEWID",
                              "PRINEARN" = "MEMBNO")) %>% 
  arrange(NEWID)
```

* Why does this give us the same answer as `left_join` for this situation?

---

## Look at the Possible Joins

```{r}
full_join(fmli, memi, by = c("NEWID" = "NEWID",
                             "PRINEARN" = "MEMBNO")) %>% 
  arrange(NEWID)
```

---

## Joining Tips

```{r}
fmli <- left_join(fmli, memi, by = c("NEWID" = "NEWID",
                                     "PRINEARN" = "MEMBNO")) %>% 
  arrange(NEWID)
```

* FIRST: conceptualize for yourself what you think you want the final dataset to look like!
* Check initial dimensions and final dimensions.
* Use variable names when joining even if they are the same.  


---

class: middle, center

## Quick Survey Time

### Once you have received the survey, provide your responses here:

# [https://bit.ly/stat100-survey](https://bit.ly/stat100-survey)

---

class: inverse, middle, center


## Data Collection


```{r, echo = FALSE, out.width='50%'}
knitr::include_graphics("img/twitter-study-design.png")
```



---

##  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/week4.002.jpeg")
```

--

**Key questions:**

+ What evidence is there that the data are **representative**?
+ Who is present?  Who is absent?
+ Who is overrepresented?  Who is underrepresented?

---

##  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/week4.003.jpeg")
```

--

**Census**: We have data on the whole population!

---

##  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='90%'}
knitr::include_graphics("img/sampling.002.jpeg")
```

---

##  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/week4.005.jpeg")
```

--


**Key questions:**

+ What evidence is there that the data are **representative**?
+ Who is present?  Who is absent?
+ Who is overrepresented?  Who is underrepresented?

---

## Sampling Bias

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/sampling.001.jpeg")
```

**Sampling bias**: When the sampled units are **systematically different** from the non-sampled units on the variables of interest.

---

### Sampling Bias Example

The **Literary Digest** was a political magazine that correctly predicted the presidential outcomes from 1916 to 1932.  In 1936, they conducted the most extensive (to that date) public opinion poll.  They mailed questionnaires to over **10 million people** (about 1/3 of US households) whose names and addresses they obtained from telephone books and vehicle registration lists.  More than 2.4 million responded with 57% indicating that they would vote for Republican Alf Landon in the upcoming presidential election instead of the current President Franklin Delano Roosevelt.

--

**Population of Interest**:

<br>

**Sample**:

<br>

**Key questions:**

+ What evidence is there that the data are **representative**?
+ Who is present?  Who is absent?
+ Who is overrepresented?  Who is underrepresented?


**Sampling bias**:


---

## Random Sampling

Use random sampling (a random mechanism for selecting cases from the population) to remove sampling bias.


#### Types of random sampling

* Simple random sampling

* Stratified random sampling

* Cluster sampling

--

Why aren't all samples generated using simple random sampling?

---

## National Health and Nutrition Examination Survey (NHANES)

Why are these data collected?

--

&rarr; To assess the health of people in the US.

--

How are these data collected?

--

&rarr; **Stage 1**: US is stratified by geography and distribution of minority populations.  Counties are randomly selected within each stratum.

--

&rarr; **Stage 2**: From the sampled counties, city blocks are randomly selected. (City blocks are clusters.)

--

&rarr; **Stage 3**: From sampled city blocks, households are randomly selected. (Household are clusters.)

--

&rarr; **Stage 4**: From sampled households, people are randomly selected.  For the sampled households, a mobile health vehicle goes to the house and medical professionals take the necessary measurements.

--

**Why don't they use simple random sampling?**

---

### Careful Using Non-SRS Data

.pull-left[

```{r, echo = FALSE}
library(NHANES)
library(tidyverse)

ggplot(data = NHANESraw, mapping = aes(x = fct_infreq(Race1),
                                    fill = Race1)) +
  geom_bar() + labs(x = "Race of Respondents", 
                    y = "Count",
                    title = "Original NHANES Data") +
  guides(fill = 'none')
```


]


--

.pull-right[

```{r, echo = FALSE}

ggplot(data = NHANES, mapping = aes(x = fct_infreq(Race1),
                                    fill = Race1)) +
  geom_bar() + labs(x = "Race of Respondents", 
                    y = "Count",
                    title = "NHANES Data Adjusted to Mimic SRS") +
  guides(fill = 'none')
```

]

--

* If you are dealing with data collected using a complex sampling design, I'd recommend taking an additional stats course, like Stat 160: Sample Surveys!

---

class: middle, center, inverse

## Detour: Data Ethics

---

### Data Ethics

> "Good statistical practice is fundamentally based on transparent assumptions, reproducible results, and valid interpretations." -- Committee on Professional Ethics of the American Statistical Association (ASA)

--

The ASA have created ["Ethical Guidelines for Statistical Practice"](https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx)

--

&rarr; These guidelines are for EVERYONE doing statistical work. 

--

&rarr; There are ethical decisions at all steps of the Data Analysis Process.

--

&rarr; We will periodically refer to specific guidelines throughout this class.

--

> "Above all, professionalism in statistical practice presumes the goal of advancing knowledge while avoiding harm; using statistics in pursuit of unethical ends is inherently unethical."

---

class: inverse, center, middle

##  Responsibilities to Research Subjects


> "The ethical statistician protects and respects the rights and interests of human and animal subjects at all stages of their involvement in a project. This includes respondents to the census or to surveys, those whose data are contained in administrative records, and subjects of physically or psychologically invasive research."

---

##  Responsibilities to Research Subjects


> "Protects the privacy and confidentiality of research subjects and data concerning them, whether obtained from the subjects directly, other persons, or existing records."


```{r, echo = FALSE, fig.asp = 0.65}
library(tidyverse)
library(NHANES)
ggplot(data = NHANES, mapping = aes(x = Age, y = Height)) +
  geom_point(alpha = 0.1) +
  stat_smooth() +
  labs("NHANES: Age versus Height")
```


---

class: middle, center, inverse

## Back to Data Collection

---

###  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='90%'}
knitr::include_graphics("img/sampling.002.jpeg")
```


---

###  Who are the data supposed to represent?

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/week4.006.jpeg")
```


**Key questions:**

+ What evidence is there that the data are **representative**?
+ Who is present?  Who is absent?
+ Who is overrepresented?  Who is underrepresented?

---

## Nonresponse bias


```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/sampling.003.jpeg")
```

**Nonresponse bias**: The respondents are **systematically** different from the non-respondents for the variables of interest.


---

### Come Back to Literary Digest Example

The **Literary Digest** was a political magazine that correctly predicted the presidential outcomes from 1916 to 1932.  In 1936, they conducted the most extensive (to that date) public opinion poll.  They mailed questionnaires to over **10 million people** (about 1/3 of US households) whose names and addresses they obtained from telephone books and vehicle registration lists.  More than 2.4 million responded with 57% indicating that they would vote for Republican Alf Landon in the upcoming presidential election instead of the current President Franklin Delano Roosevelt.

<br>

**Non-response bias**:


---

## Tackling Nonresponse bias


```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/sampling.003.jpeg")
```

--

&rarr; Use multiple modes and multiple attempts for reaching sampled cases.

--

&rarr; Explore key demographic variables to see how respondents and non-respondents vary.

---

## Is Bigger Always Better?

--

```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/sampling.004.jpeg")
```

--

For our **Literary Digest Example**, Gallup predicted Roosevelt would win based on a survey of **50,000** people, (instead of 2.4 million).

---

### Big Data Paradox


```{r, echo = FALSE, out.width= "10%", out.extra='style="float:left; padding:10px"'}
knitr::include_graphics("img/meng.jpg")
```

> "Without taking data quality into account, population inferences with Big Data are subject to a Big Data Paradox: the more the data, the surer we fool ourselves." -- Xiao-Li Meng


--

**Example:** 

* During Spring of 2021, Delphi-Facebook estimated  vaccine uptake at 70% and U.S. Census estimated it at 67%.

--

* The CDC reported it to be 53%.

--

And, once we learn about **quantifying uncertainty**, we will see that large sample sizes produce very small measures of uncertainty.

--

> "If you have the resources, invest in data quality far more than you invest in data quantity. Bad-quality data is essentially wiping out the power you think you have. That’s always been a problem, but it’s magnified now because we have big data. " -- Xiao-Li Meng

---

## Other Key Random Mechanism: Random Assignment

--

**Random assignment**: Cases are randomly assigned to categories of the **explanatory variable**

* **Response variable**: Variable I want to better understand

* **Explanatory variables**: Variables I think might explain the response variable

--

&rarr; If the data were collected using **random assignment**, then I can determine if the explanatory variable **causes** changes in the response variable.


---

## Causal Inference

Often want to conclude that an explanatory variable causes changes in a response variable but you did not randomly assign the explanatory variable.

--

**Confounding variable**: When the explanatory variable and response variable vary, so does the confounder.

&rarr; Unclear if the explanatory variable or the confounder (or some other variable) is causing changes in the response.


```{r  out.width = "70%", echo=FALSE, fig.align='center'}
include_graphics("img/confound.png")
```

---

## Causal Inference

Often want to conclude that an explanatory variable causes changes in a response variable but you did not randomly assign the explanatory variable.



**Confounding variable**: When the explanatory variable and response variable vary, so does the confounder.

&rarr; Unclear if the explanatory variable or the confounder (or some other variable) is causing changes in the response.


```{r  out.width = "70%", echo=FALSE, fig.align='center'}
include_graphics("img/confound2.png")
```

---

## Causal Inference

* **Spurious relationship**: Two variables are associated but not causally related
    + In the age of big data, lots of good examples [out there](https://tylervigen.com/spurious-correlations).

--

> "Correlation does not imply causation."

--

>  "Correlation does not imply not causation."

--

* **Causal inference**: Methods for finding causal relationships even when the data were collected without random assignment.


---

## Types of Studies

**Observational Study:** Collect data in a way that doesn't interfere

--

&rarr; **Example**: Studies of hand washing frequency

--

**Experiment:** Interested in causal relationships so utilize random assignment.  Other key features include:

+ Blinding
+ Control group
+ Placebo

--

&rarr; **Example**: COVID vaccine trials


---

## Thoughts on Data Collection

**Random Sampling**


Random sampling is important to ensure the sample is representative of the population.

--

Representativeness isn't about size.

+ Small random samples will tend to be more representative than large non-random samples.

--

How do we draw conclusions about the population from non-random samples?

--

&rarr; Investigate how your sampled cases (and respondents) are systematically different from the non-sampled cases (and non-respondents).

---

## Thoughts on Data Collection

**Random Assignment**

Random assignment allows you to explore **causal** relationships between your explanatory variables and the predictor variables.

--

How do we draw causal conclusions from studies without random assignment?

--

&rarr; With extreme care!  Try to control for all possible confounding variables.

--

&rarr; Discuss the associations/correlations you found.  Use domain knowledge to address potentially causal links.

--

&rarr; Take more stats to learn more about causal inference.


--

**Bottom Line:** We often have to use imperfect data to make decisions.


---

## Two Key Random Mechanisms


```{r, echo = FALSE, out.width='80%'}
knitr::include_graphics("img/ims_ch2.png")
```



---

### Reminders


* **Participation/Engagement:**
    + In class and section
    + Office hours: Must attend **at least one** office hours during the first five weeks of the semester
    + On Slack: **At least two** posts before Spring Break

* Will practice applying data collection ideas in Section this week!

